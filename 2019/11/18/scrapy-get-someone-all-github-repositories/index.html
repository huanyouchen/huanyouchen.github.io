<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="python，Java，hacker"><title>基于Scrapy爬虫框架获取GitHub某用户全部仓库的信息 | 幻悠尘的小窝</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create','UA-118684665-1','auto');ga('send','pageview');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + '6630ddc4c60afb15b88971c6ab1d81a8';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 4.2.1"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">基于Scrapy爬虫框架获取GitHub某用户全部仓库的信息</h1><a id="logo" href="/.">幻悠尘的小窝</a><p class="description">The quieter you become,the more you are able to hear.</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/tags/"><i class="fa fa-tags"> 标签</i></a><a href="/projects/"><i class="fa fa-github"> 作品</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/message-board/"><i class="fa fa-comments"> 留言</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-4-4"><div class="content_container"><div class="post"><h1 class="post-title">基于Scrapy爬虫框架获取GitHub某用户全部仓库的信息</h1><div class="post-content"><p>本文内容来自实验楼Scrapy 爬虫框架基础实践及挑战课程：<a href="https://www.shiyanlou.com/courses/1417" target="_blank" rel="noopener">https://www.shiyanlou.com/courses/1417</a><br>源码：<a href="https://github.com/shiyanlou/louplus-dm/tree/v2/Answers/week1-challenge-05" target="_blank" rel="noopener">https://github.com/shiyanlou/louplus-dm/tree/v2/Answers/week1-challenge-05</a></p>
<p>使用方法：</p>
<ul>
<li>下载项目源码</li>
<li>打开spiders目录下的github_repositories_autonext文件，修改start_urls函数中的GitHub仓库所有者名字，如把<code>https://github.com/shiyanlou?tab=repositories</code>修改为<code>https://github.com/huanyouchen?tab=repositories</code></li>
<li>在项目目录下，执行<code>scrapy crawl github_repositories_autonext</code>命令</li>
<li>查看下载完成的csv文件内容</li>
</ul>
<h3 id="Scrapy的基本结构"><a href="#Scrapy的基本结构" class="headerlink" title="Scrapy的基本结构"></a>Scrapy的基本结构</h3><p>Scrapy结构图如下：</p>
<p><img src="https://huanyouchen-1252081928.cos.ap-shanghai.myqcloud.com/2019-11-18-scrapy-basic-jiegou.png" alt="Scrapy结构"></p>
<p>Scrapy 的组件包括：</p>
<ul>
<li>Scrapy Engine：处理系统数据流和事务的引擎。</li>
<li>Scheduler 和 Scheduler Middlewares：调度引擎发过来的请求。</li>
<li>Downloader 和 Downloader Middlewares：下载网页内容的下载器。</li>
<li>Spider ：爬虫系统，处理域名解析规则及网页解析。</li>
</ul>
<p>Scrapy 的基本用法包括下面几个步骤：</p>
<ul>
<li>初始化 Scrapy 项目。</li>
<li>实现 Item，用来存储提取信息的容器类。</li>
<li>实现 Spider，用来爬取数据的爬虫类。</li>
<li>从 HTML 页面中提取数据到 Item。</li>
<li>实现 Item Pipeline 来保存 Item 数据。</li>
</ul>
<h3 id="爬虫目标"><a href="#爬虫目标" class="headerlink" title="爬虫目标"></a>爬虫目标</h3><p>指定用户ID: shiyanlou</p>
<p>目标页面：<a href="https://github.com/shiyanlou?tab=repositories" target="_blank" rel="noopener">https://github.com/shiyanlou?tab=repositories</a></p>
<p>获取指定GitHub 用户的所有仓库名称，以及仓库更新时间，将爬到的数据保存为csv文件。</p>
<h3 id="初始化-Scrapy-项目。"><a href="#初始化-Scrapy-项目。" class="headerlink" title="初始化 Scrapy 项目。"></a>初始化 Scrapy 项目。</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 创建爬虫演示目录</span><br><span class="line">mkdir scrapy-demo</span><br><span class="line">cd scrapy-demo</span><br><span class="line"></span><br><span class="line"># 初始化项目</span><br><span class="line">scrapy startproject get_github_repositories</span><br><span class="line">cd get_github_repositories&#x2F;</span><br><span class="line">scrapy genspider github_repositories github.com</span><br></pre></td></tr></table></figure>
<p>其中，爬虫项目名称是<code>get_github_repositories</code>， 爬虫名称是<code>github_repositories</code>。</p>
<h3 id="实现-Item，用来存储提取信息的容器类。"><a href="#实现-Item，用来存储提取信息的容器类。" class="headerlink" title="实现 Item，用来存储提取信息的容器类。"></a>实现 Item，用来存储提取信息的容器类。</h3><p>由于爬虫目标信息是要获取每个仓库的名称和更新时间，因此在Item中写入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GetGithubRepositoriesItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    repo_name = scrapy.Field()</span><br><span class="line">    update_time = scrapy.Field()</span><br></pre></td></tr></table></figure>

<h3 id="实现-Spider，用来爬取数据的爬虫类。"><a href="#实现-Spider，用来爬取数据的爬虫类。" class="headerlink" title="实现 Spider，用来爬取数据的爬虫类。"></a>实现 Spider，用来爬取数据的爬虫类。</h3><p>分析目标页面的结构，找出需要的仓库名字和时间，</p>
<p><img src="https://huanyouchen-1252081928.cos.ap-shanghai.myqcloud.com/2019-11-18-scrapy-github-cangku.png" alt="github 个人仓库页面"></p>
<p>可以看出，每个仓库名字和更新时间，都是在ul-&gt;li列表下，其中，名字在属性为<code>itemprop=&#39;name codeRepository&#39;</code>的a标签下，更新时间在<code>relative-time</code>中，分别使用xpath解析可以得到其内容。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">    repos = response.xpath(<span class="string">'//li[@itemprop="owns"]'</span>)</span><br><span class="line">    <span class="keyword">for</span> repo <span class="keyword">in</span> repos:</span><br><span class="line">         item = GetGithubRepositoriesItem()</span><br><span class="line">         item[<span class="string">'repo_name'</span>] = repo.xpath(<span class="string">".//a[@itemprop='name codeRepository']/text()"</span>).extract_first().strip()</span><br><span class="line">         item[<span class="string">'update_time'</span>] = repo.xpath(<span class="string">".//relative-time/@datetime"</span>).extract_first()</span><br><span class="line"></span><br><span class="line">         <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>

<p>得到第一页内容后，需要往后翻页，得到后面几页所有的仓库信息。点击下一页，观察URL发现，URL内容为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;github.com&#x2F;shiyanlou?after&#x3D;Y3Vyc29yOnYyOpK5MjAxNC0xMC0xM1QxMToxNTo0NCswODowMM4Bf5tW&amp;tab&#x3D;repositories</span><br></pre></td></tr></table></figure>
<p>下一页的地址通过after参数控制。关键是获取after参数的内容，然后加入到url里，就可以得到下一页的内容。</p>
<p>先介绍第一种方法，手动复制所有的页面的after参数，放在列表中，然后遍历即可</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@property</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">start_urls</span><span class="params">(self)</span>:</span></span><br><span class="line">    url_temp =  <span class="string">'https://github.com/shiyanlou?after=&#123;&#125;&amp;tab=repositories'</span></span><br><span class="line">    after = [</span><br><span class="line">        <span class="string">""</span>,   <span class="comment"># 第一页没有after参数</span></span><br><span class="line">        <span class="string">"Y3Vyc29yOnYyOpK5MjAxNy0wNi0wN1QwODozMjo1OCswODowMM4FkpUU"</span>,</span><br><span class="line">        <span class="string">"Y3Vyc29yOnYyOpK5MjAxNS0wMi0xMFQxMzowODo0NyswODowMM4B0o4T"</span>,</span><br><span class="line">        <span class="string">"Y3Vyc29yOnYyOpK5MjAxNC0xMi0wN1QyMjoxMTozNSswODowMM4Bpo1E"</span>,</span><br><span class="line">        <span class="string">"Y3Vyc29yOnYyOpK5MjAxNC0xMC0xM1QxMToxNTo0NCswODowMM4Bf5tW"</span></span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> (url_temp.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> after)</span><br></pre></td></tr></table></figure>

<h3 id="实现-Item-Pipeline-来保存-Item-数据"><a href="#实现-Item-Pipeline-来保存-Item-数据" class="headerlink" title="实现 Item Pipeline 来保存 Item 数据"></a>实现 Item Pipeline 来保存 Item 数据</h3><p>把爬到的数据通过Pandas保存为csv文件，需要在爬虫启动和关闭时，分别设置相应的操作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GetGithubRepositoriesPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="comment"># 读取 item 数</span></span><br><span class="line">        repo_name = item[<span class="string">'repo_name'</span>]</span><br><span class="line">        update_time = item[<span class="string">'update_time'</span>]</span><br><span class="line">        <span class="comment"># 每条数据组成临时 df_temp</span></span><br><span class="line">        df_temp = pd.DataFrame([[repo_name, update_time]], columns=[<span class="string">'repo_name'</span>, <span class="string">'update_time'</span>])</span><br><span class="line">        <span class="comment"># 将 df_temp 合并到 df</span></span><br><span class="line">        self.df = self.df.append(df_temp, ignore_index=<span class="literal">True</span>).sort_values(by=[<span class="string">'update_time'</span>], ascending=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#当爬虫启动时</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="comment"># 新建一个带列名的空白 df</span></span><br><span class="line">        self.df = pd.DataFrame(columns=[<span class="string">'repo_name'</span>, <span class="string">'update_time'</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 当爬虫关闭时</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">close_spider</span><span class="params">(self, spider)</span>:</span></span><br><span class="line">        <span class="comment"># 将 df 存储为 csv 文件</span></span><br><span class="line">        pd.DataFrame.to_csv(self.df, <span class="string">"../shiyanlou_repo.csv"</span>)</span><br></pre></td></tr></table></figure>

<p>最后，在setting设置中，把下面内容的注释取消</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">    <span class="string">'get_github_repositories.pipelines.GetGithubRepositoriesPipeline'</span>: <span class="number">300</span>,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>并把ROBOTSTXT_OBEY改为False</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Obey robots.txt rules</span></span><br><span class="line">ROBOTSTXT_OBEY = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<h3 id="执行爬虫程序"><a href="#执行爬虫程序" class="headerlink" title="执行爬虫程序"></a>执行爬虫程序</h3><p>在爬虫项目目录，执行下面命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl github_repositories</span><br></pre></td></tr></table></figure>

<hr>
<h3 id="第二种方法，自动获取after参数"><a href="#第二种方法，自动获取after参数" class="headerlink" title="第二种方法，自动获取after参数"></a>第二种方法，自动获取after参数</h3><p>在项目目录，新建另一个爬虫，实现自动获取after参数</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy genspider github_repositories_autonext github.com</span><br></pre></td></tr></table></figure>

<p>通过Chrome的开发者工具，查看next按钮对应的HTML代码，</p>
<p>当有下一页时</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"BtnGroup"</span> <span class="attr">data-test-selector</span>=<span class="string">"pagination"</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">button</span> <span class="attr">class</span>=<span class="string">"btn btn-outline BtnGroup-item"</span> <span class="attr">disabled</span>=<span class="string">"disabled"</span>&gt;</span>Previous<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">a</span> <span class="attr">rel</span>=<span class="string">"nofollow"</span> <span class="attr">class</span>=<span class="string">"btn btn-outline BtnGroup-item"</span> <span class="attr">href</span>=<span class="string">"https://github.com/shiyanlou?after=Y3Vyc29yOnYyOpK5MjAxNy0wNi0wN1QwODozMjo1OCswODowMM4FkpUU<span class="symbol">&amp;amp;</span>tab=repositories"</span>&gt;</span>Next<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"BtnGroup"</span> <span class="attr">data-test-selector</span>=<span class="string">"pagination"</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">a</span> <span class="attr">rel</span>=<span class="string">"nofollow"</span> <span class="attr">class</span>=<span class="string">"btn btn-outline BtnGroup-item"</span> <span class="attr">href</span>=<span class="string">"https://github.com/shiyanlou?before=Y3Vyc29yOnYyOpK5MjAxNy0wNi0wN1QwODozMDowOSswODowMM4FkpM6<span class="symbol">&amp;amp;</span>tab=repositories"</span>&gt;</span>Previous<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;<span class="name">a</span> <span class="attr">rel</span>=<span class="string">"nofollow"</span> <span class="attr">class</span>=<span class="string">"btn btn-outline BtnGroup-item"</span> <span class="attr">href</span>=<span class="string">"https://github.com/shiyanlou?after=Y3Vyc29yOnYyOpK5MjAxNS0wMi0xMFQxMzowODo0NyswODowMM4B0o4T<span class="symbol">&amp;amp;</span>tab=repositories"</span>&gt;</span>Next<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>当没有下一页时：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"BtnGroup"</span> <span class="attr">data-test-selector</span>=<span class="string">"pagination"</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">a</span> <span class="attr">rel</span>=<span class="string">"nofollow"</span> <span class="attr">class</span>=<span class="string">"btn btn-outline BtnGroup-item"</span> <span class="attr">href</span>=<span class="string">"https://github.com/shiyanlou?before=Y3Vyc29yOnYyOpK5MjAxNC0xMC0xMVQwNDowMDoyMiswODowMM4Bgd5Q<span class="symbol">&amp;amp;</span>tab=repositories"</span>&gt;</span>Previous<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">button</span> <span class="attr">class</span>=<span class="string">"btn btn-outline BtnGroup-item"</span> <span class="attr">disabled</span>=<span class="string">"disabled"</span>&gt;</span>Next<span class="tag">&lt;/<span class="name">button</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>可以看出：</p>
<ul>
<li>如果 Next 按钮没有被禁用，那么表示有下一页，下一页的after参数在a标签的href属性中</li>
<li>如果 Next 按钮被禁用，那么表示没有下一页，下一页的button的disabled属性</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> shiyanlou.items <span class="keyword">import</span> ShiyanlouItem</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">GithubSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'github_next_page'</span></span><br><span class="line">    allowed_domains = [<span class="string">'github.com'</span>]</span><br><span class="line"></span><br><span class="line"><span class="meta">    @property</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_urls</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> (<span class="string">'https://github.com/shiyanlou?tab=repositories'</span>, )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        repos = response.xpath(<span class="string">'//li[@itemprop="owns"]'</span>)</span><br><span class="line">        <span class="keyword">for</span> repo <span class="keyword">in</span> repos:</span><br><span class="line">            item = ShiyanlouItem()</span><br><span class="line">            item[<span class="string">'repo_name'</span>] = repo.xpath(<span class="string">".//a[@itemprop='name codeRepository']/text()"</span>).extract_first().strip()</span><br><span class="line">            item[<span class="string">'update_time'</span>] = repo.xpath(<span class="string">".//relative-time/@datetime"</span>).extract_first()</span><br><span class="line"></span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果 Next 按钮没被禁用，那么表示有下一页</span></span><br><span class="line">        spans = response.css(<span class="string">'div.pagination span.disabled::text'</span>)</span><br><span class="line">        <span class="keyword">if</span> len(spans) == <span class="number">0</span> <span class="keyword">or</span> spans[<span class="number">-1</span>].extract() != <span class="string">'Next'</span>:</span><br><span class="line">            next_url = response.css(<span class="string">'div.paginate-container a:last-child::attr(href)'</span>).extract_first()</span><br><span class="line">            <span class="keyword">yield</span> response.follow(next_url, callback=self.parse)</span><br></pre></td></tr></table></figure>

<p>在爬虫项目目录，执行下面命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl github_repositories_autonext</span><br></pre></td></tr></table></figure></div></div><div id="disqus_thread"><div class="btn_click_load"><button class="disqus_click_btn">阅读评论（请确保 Disqus 可以正常加载）</button></div><script type="text/javascript">var disqus_config = function () {
    this.page.url = 'http://huanyouchen.github.io/2019/11/18/scrapy-get-someone-all-github-repositories/';
    this.page.identifier = '2019/11/18/scrapy-get-someone-all-github-repositories/';
    this.page.title = '基于Scrapy爬虫框架获取GitHub某用户全部仓库的信息';
  };</script><script type="text/javascript" id="disqus-lazy-load-script">$.ajax({
url: 'https://disqus.com/next/config.json',
timeout: 2500,
type: 'GET',
success: function(){
  var d = document;
  var s = d.createElement('script');
  s.src = '//huanyouchen-blog.disqus.com/embed.js';
  s.setAttribute('data-timestamp', + new Date());
  (d.head || d.body).appendChild(s);
  $('.disqus_click_btn').css('display', 'none');
},
error: function() {
  $('.disqus_click_btn').css('display', 'block');
}
});</script><script type="text/javascript" id="disqus-click-load">$('.btn_click_load').click(() => {  //click to load comments
    (() => { // DON'T EDIT BELOW THIS LINE
        var d = document;
        var s = d.createElement('script');
        s.src = '//huanyouchen-blog.disqus.com/embed.js';
        s.setAttribute('data-timestamp', + new Date());
        (d.head || d.body).appendChild(s);
    })();
    $('.disqus_click_btn').css('display','none');
});</script><script type="text/javascript" id="disqus-count-script">$(function() {
     var xhr = new XMLHttpRequest();
     xhr.open('GET', '//disqus.com/next/config.json', true);
     xhr.timeout = 2500;
     xhr.onreadystatechange = function () {
       if (xhr.readyState === 4 && xhr.status === 200) {
         $('.post-meta .post-comments-count').show();
         var s = document.createElement('script');
         s.id = 'dsq-count-scr';
         s.src = 'https://huanyouchen-blog.disqus.com/count.js';
         s.async = true;
         (document.head || document.body).appendChild(s);
       }
     };
     xhr.ontimeout = function () { xhr.abort(); };
     xhr.send(null);
   });
</script></div></div></div><div class="pure-u-1 pure-u-md-4-4"><div id="footer">Copyright © 2020 <a href="/." rel="nofollow">幻悠尘的小窝.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
</script><script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML" async></script><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>